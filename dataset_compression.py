import torchvision.transforms as transforms
from torchvision import datasets


def save_list_to_txt(file_save_path, data_list):
    # Convert the list to a string representation
    list_string = "\n".join(map(str, data_list))

    try:
        with open(file_save_path, "w") as file:
            file.write(list_string)
        print(f"List saved to '{file_save_path}' successfully.")
    except Exception as e:
        print(f"An error occurred while saving the list: {e}")


def main():
    import argparse
    import os
    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset", help="cifar10, stl10")
    parser.add_argument("--crq", type=int, help="compression quality (0-100, where 0 corresponds to the highest "
                                                "compression and 100 is lossless)")
    parser.add_argument("--train_or_val")
    parser.add_argument("--data_storage_dir", help="root directory to save original and compressed datasets")

    args = parser.parse_args()
    compression_quality = args.crq
    dataset_name = args.dataset
    train_or_val = args.train_or_val
    data_storage_dir = args.data_storage_dir

    transform = transforms.Compose([transforms.ToTensor()])
    # file_save_dir = f"/media/cangxiong/storage/datasets/{dataset_name}_compressed/labels"
    file_save_dir = os.path.join(data_storage_dir, f"{dataset_name}_compressed/labels")
    file_save_path = os.path.join(file_save_dir, f"{train_or_val}_labels.txt")
    # Create a directory to save the compressed images
    # compressed_images_dir = f"/media/cangxiong/storage/datasets/{dataset_name}_compressed/images_compr_{compression_quality}/{train_or_val}"
    compressed_images_dir = os.path.join(data_storage_dir,
                                         f"{dataset_name}_compressed/images_compr_{compression_quality}/{train_or_val}")
    if not os.path.exists(compressed_images_dir):
        # If it doesn't exist, create it
        os.makedirs(compressed_images_dir)
        print(f"Directory '{compressed_images_dir}' created successfully.")
    else:
        print(f"Directory '{compressed_images_dir}' already exists.")

    original_images_dir = os.path.join(data_storage_dir, f"{dataset_name}")
    if dataset_name == 'cifar10':
        if train_or_val == 'val':
            dataset = datasets.CIFAR10(root=original_images_dir, train=False,
                                       download=True, transform=transform)
        elif train_or_val == 'train':
            dataset = datasets.CIFAR10(root=original_images_dir, train=True,
                                       download=True, transform=transform)
    elif dataset_name == 'stl10':
        if train_or_val == 'val':
            dataset = datasets.STL10(root=original_images_dir, split='test',
                                     download=False, transform=transform)
        elif train_or_val == 'train':
            dataset = datasets.STL10(root=original_images_dir, split='train',
                                     download=False, transform=transform)

    # Compress and save the images
    label_set = []
    for i, (image, label) in enumerate(dataset):
        image_path = os.path.join(compressed_images_dir, f'{i:05d}.jpg')
        pil_image = transforms.ToPILImage()(image)
        pil_image.save(image_path, quality=compression_quality)
        label_set.append(label)

    print(f"Compressed images saved to {compressed_images_dir}\n")
    # save the labels to a text file.
    os.makedirs(file_save_dir, exist_ok=True)
    save_list_to_txt(file_save_path, label_set)


if __name__ == "__main__":
    main()




