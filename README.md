# Understanding the Vulnerability of CLIP to Image Compression [[paper]](https://arxiv.org/abs/2311.14029)

## Abstract
CLIP is a widely used foundational vision-language model that is used for zero-shot image recognition and other
image-text alignment tasks. We demonstrate that CLIP is vulnerable to change in image quality under compression. 
This surprising result is further analysed using an attribution method-Integrated Gradients. 
Using this attribution method, we are able to better understand both quantitatively and qualitatively exactly the 
nature in which the compression affects the zero-shot recognition accuracy of this model. 
We evaluate this extensively on CIFAR-10 and STL-10. Our work provides the basis to understand this vulnerability of 
CLIP and can help us develop more effective methods to improve the robustness of CLIP and other vision-language models.

## Implementation
In this section, we will show how to reproduce the empirical results from our paper. 

First, create a virtual environment:
```
conda create -n clip 
```
Then follow https://github.com/openai/CLIP#usage and install CLIP:
```
conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0
pip install ftfy regex tqdm
pip install git+https://github.com/openai/CLIP.git
```
